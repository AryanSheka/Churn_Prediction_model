# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/182F7sjwPi-cHu-MAHVBd2yIcTdyASHCv

Importing Necessary Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""Importing the Data Set and removing non necessary columns"""

df = pd.read_csv('/kaggle/input/churn-modelling/Churn_Modelling.csv')
df.drop(['RowNumber','CustomerId'],inplace=True,axis=1)

"""Choosing Features and Converting Categorical data into numerical using Dummy encoding"""

X = df.iloc[:,1:10]
y=df.iloc[:,11]
gender= pd.get_dummies(df['Gender'],drop_first=True)
geo=pd.get_dummies(df['Geography'],drop_first=True)
X=pd.concat([X,geo,gender],axis=1)
X=X.drop(['Geography','Gender'],axis=1)

"""Feature Scaling"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=0)

sc = StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.fit_transform(X_test)

"""Hyperparameter tuning"""

import keras
from keras import layers
from keras import callbacks
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV

def create_model(layers,activation):
    model= keras.Sequential()
    for i, nodes in enumerate(layers):
        if i==0:
            model.add(Dense(nodes,input_shape=X_train.shape[0]))
            model.add(Activation(activation))
            model.add(Dropout(0.3))
        else:
            model.add(Dense(nodes))
            model.add(Activation(activation))
            model.add(Dropout(0.3))
        model.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))
    return model

test_model=KerasClassifier(build_fn=create_model,verbose=0)

layers =[[300],[256,256,128,256],[128,128,128,128],[256,256,256,256],[300,256,128]]
activations =['sigmoid','relu']

param_grid = dict(layers=layers,activation=activations,batch_size=[128,256],epochs=300)
grid=GridSearchCV(estimator=test_model,param_grid=param_grid,cv=5)
grid_result=grid.fit(X_train,X_test)
print(grid_result.best_score_,grid_result.best_params_)


"""Training model """

model = keras.Sequential([layers.Dense(300,input_shape=[10],activation='relu',kernel_initializer='he_normal'),
                          layers.Dropout(rate=0.3),
                          layers.Dense(256,activation='relu',kernel_initializer='he_normal'),
                          layers.Dropout(rate=0.3),
                          layers.Dense(128,activation='relu',kernel_initializer='he_normal'),
                          layers.Dense(1,activation='sigmoid',kernel_initializer='glorot_normal')
                         ])

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
cc=callbacks.EarlyStopping(min_delta=0.001,patience=20,restore_best_weights=True)
hist= model.fit(X_train,y_train,validation_split=0.33,batch_size=128,epochs=500,callbacks=[cc])

histo= pd.DataFrame(hist.history)

"""Plotting Loss against Epoch"""

import plotly 
import plotly.express as px
import plotly.graph_objects as go
import plotly.offline as pyo
from plotly.offline import init_notebook_mode
hist2 = histo.loc[:,['loss']]
lis= pd.DataFrame({'epoch':[int(i) for i in range(1,len(hist2)+1)]})
hist2=pd.concat([hist2,lis],axis=1)
fig = px.line(hist2,x='epoch',y='loss')
fig.update_layout()
fig.show()

"""Testing the Model and viewing accuracy"""

from sklearn.metrics import accuracy_score

y_pred=model.predict(X_test)
y_pred=(y_pred>0.5)

score=accuracy_score(y_pred,y_test)
score
